{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils import CustomPreprocessor, ModelSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before dropping duplicates 12139\n",
      "After dropping duplicates 8573\n"
     ]
    }
   ],
   "source": [
    "df_sentences = pd.read_csv('../../raw_data/labeled_sentences_merged_imbalanced_12k_extra_classes.csv',usecols=['sentence','topic_label','sentiment_label'])\n",
    "print(f'Before dropping duplicates {len(df_sentences)}')\n",
    "df_sentences.drop_duplicates(inplace=True)\n",
    "print(f'After dropping duplicates {len(df_sentences)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before dropping duplicates 4525\n",
      "After dropping duplicates 3115\n"
     ]
    }
   ],
   "source": [
    "df_articles = pd.read_csv('../../raw_data/volkswagon_news_text.csv',usecols=['full_text'])\n",
    "print(f'Before dropping duplicates {len(df_articles)}')\n",
    "df_articles.drop_duplicates(inplace=True)\n",
    "print(f'After dropping duplicates {len(df_articles)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>topic_label</th>\n",
       "      <th>sentiment_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fallout from the scandal could lead to a lost ...</td>\n",
       "      <td>Governance</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The damning parliamentary report into the demi...</td>\n",
       "      <td>Social</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The BHS scandal has been described by MPs as t...</td>\n",
       "      <td>Environmental</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dominic Chappell, the businessman who bought B...</td>\n",
       "      <td>Social</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The fallout from the scandal could lead to a k...</td>\n",
       "      <td>Governance</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12133</th>\n",
       "      <td>Seoul-based Daol Investment &amp; Securities analy...</td>\n",
       "      <td>None</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12134</th>\n",
       "      <td>\"It may take a few years, but eventually the l...</td>\n",
       "      <td>Environmental</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12135</th>\n",
       "      <td>(Reporting by Heekyong Yang in Seoul and Ben K...</td>\n",
       "      <td>None</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12136</th>\n",
       "      <td>Click For Restrictions - https://agency.reuter...</td>\n",
       "      <td>None</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12137</th>\n",
       "      <td>\\n\\n        Users collect the needed &amp;Charge k...</td>\n",
       "      <td>Environmental</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8573 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence    topic_label  \\\n",
       "0      Fallout from the scandal could lead to a lost ...     Governance   \n",
       "1      The damning parliamentary report into the demi...         Social   \n",
       "2      The BHS scandal has been described by MPs as t...  Environmental   \n",
       "3      Dominic Chappell, the businessman who bought B...         Social   \n",
       "4      The fallout from the scandal could lead to a k...     Governance   \n",
       "...                                                  ...            ...   \n",
       "12133  Seoul-based Daol Investment & Securities analy...           None   \n",
       "12134  \"It may take a few years, but eventually the l...  Environmental   \n",
       "12135  (Reporting by Heekyong Yang in Seoul and Ben K...           None   \n",
       "12136  Click For Restrictions - https://agency.reuter...           None   \n",
       "12137  \\n\\n        Users collect the needed &Charge k...  Environmental   \n",
       "\n",
       "      sentiment_label  \n",
       "0            Negative  \n",
       "1            Negative  \n",
       "2            Negative  \n",
       "3             Neutral  \n",
       "4            Negative  \n",
       "...               ...  \n",
       "12133        Positive  \n",
       "12134        Positive  \n",
       "12135         Neutral  \n",
       "12136         Neutral  \n",
       "12137        Positive  \n",
       "\n",
       "[8573 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_sentences[['sentence']].astype(str)\n",
    "y_topic = df_sentences.loc[:,'topic_label'].values\n",
    "y_sentiment = df_sentences.loc[:,'sentiment_label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', CustomPreprocessor()),\n",
    "    ('vectorizer', TfidfVectorizer()),\n",
    "    ('model',ModelSelector())\n",
    "])\n",
    "# ModelSelector().get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_topic_train, X_topic_test, y_topic_train, y_topic_test = train_test_split(X,y_topic,test_size=0.25,random_state=42)\n",
    "X_sentiment_train, X_sentiment_test, y_sentiment_train, y_sentiment_test = train_test_split(X,y_sentiment,test_size=0.25,random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "[CV 1/5] END ...................model__model=NB;, score=0.608 total time=  10.6s\n",
      "[CV 4/5] END ...................model__model=NB;, score=0.619 total time=  10.6s\n",
      "[CV 5/5] END ...................model__model=NB;, score=0.618 total time=   9.3s\n",
      "[CV 2/5] END ..................model__model=SVM;, score=0.739 total time=  10.8s\n",
      "[CV 3/5] END ..................model__model=SVM;, score=0.760 total time=  10.5s\n",
      "[CV 2/5] END ...................model__model=NB;, score=0.636 total time=   9.5s\n",
      "[CV 3/5] END ...................model__model=NB;, score=0.623 total time=  10.0s\n",
      "[CV 1/5] END ..................model__model=SVM;, score=0.724 total time=   9.8s\n",
      "[CV 1/5] END ...................model__model=DT;, score=0.670 total time=  12.3s\n",
      "[CV 4/5] END ..................model__model=SVM;, score=0.733 total time=  13.9s\n",
      "[CV 5/5] END ..................model__model=SVM;, score=0.736 total time=  14.4s\n",
      "[CV 1/5] END ...................model__model=RF;, score=0.717 total time=  19.2s\n",
      "[CV 4/5] END ...................model__model=RF;, score=0.713 total time=  19.3s\n",
      "[CV 5/5] END ...................model__model=RF;, score=0.713 total time=  19.4s\n",
      "[CV 2/5] END ...................model__model=DT;, score=0.659 total time=  13.2s\n",
      "[CV 2/5] END ...................model__model=RF;, score=0.696 total time=  28.7s\n",
      "[CV 3/5] END ...................model__model=RF;, score=0.709 total time=  28.9s\n",
      "[CV 1/5] END ..................model__model=Reg;, score=0.715 total time=  12.2s\n",
      "[CV 2/5] END ..................model__model=Reg;, score=0.726 total time=  12.3s\n",
      "[CV 3/5] END ...................model__model=DT;, score=0.636 total time=  18.7s\n",
      "[CV 4/5] END ...................model__model=DT;, score=0.659 total time=  18.5s\n",
      "[CV 5/5] END ...................model__model=DT;, score=0.655 total time=  13.7s\n",
      "[CV 3/5] END ..................model__model=Reg;, score=0.729 total time=  10.8s\n",
      "[CV 4/5] END ..................model__model=Reg;, score=0.719 total time=  10.3s\n",
      "[CV 5/5] END ..................model__model=Reg;, score=0.713 total time=  10.4s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score,recall_score,precision_score,accuracy_score,make_scorer\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    # 'preprocessor__accents':['keep','remove'],\n",
    "    # 'preprocessor__html':['keep','remove'],\n",
    "    # 'preprocessor__negation':['keep','remove'],\n",
    "    # 'preprocessor__numbers':['keep','remove'],\n",
    "    # 'preprocessor__punctuation':['keep','remove'],\n",
    "    # 'preprocessor__remove_stopwords':[True,False],\n",
    "    # 'preprocessor__stem':[True,False],\n",
    "    # 'preprocessor__lemma':[True,False],\n",
    "    # 'vectorizer__max_df':[1.0,0.8],\n",
    "    # 'vectorizer__min_df':[1,10],\n",
    "    # 'vectorizer__ngram_range':[(1,1),(1,2)],\n",
    "    # 'nb__alpha':[1.0,0.9,0.7,0.5]\n",
    "    'model__model' : ['NB','SVM','RF','DT','Reg']\n",
    "    \n",
    "}\n",
    "\n",
    "# accuracy_scorer = make_scorer(accuracy_score)\n",
    "# precision_scorer = make_scorer(precision_score)\n",
    "# recall_scorer = make_scorer(recall_score)\n",
    "f1_scorer = make_scorer(f1_score)\n",
    "# Define the grid search\n",
    "topic_grid = GridSearchCV(pipeline, param_grid, cv=5, n_jobs=-1,scoring='f1_weighted',verbose=3,error_score='raise').fit(X_topic_train, y_topic_train)\n",
    "# sentiment_grid = GridSearchCV(pipeline, param_grid, cv=5, n_jobs=-1,scoring='f1_weighted',verbose=2,error_score='raise').fit(X_sentiment_train, y_sentiment_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cv_results = pd.DataFrame(topic_grid.cv_results_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_model__model</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.353714</td>\n",
       "      <td>1.198838</td>\n",
       "      <td>2.517534</td>\n",
       "      <td>0.719666</td>\n",
       "      <td>SVM</td>\n",
       "      <td>{'model__model': 'SVM'}</td>\n",
       "      <td>0.724249</td>\n",
       "      <td>0.738953</td>\n",
       "      <td>0.760413</td>\n",
       "      <td>0.732710</td>\n",
       "      <td>0.736469</td>\n",
       "      <td>0.738559</td>\n",
       "      <td>0.012009</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.493708</td>\n",
       "      <td>0.587190</td>\n",
       "      <td>1.716945</td>\n",
       "      <td>0.320112</td>\n",
       "      <td>Reg</td>\n",
       "      <td>{'model__model': 'Reg'}</td>\n",
       "      <td>0.715037</td>\n",
       "      <td>0.725852</td>\n",
       "      <td>0.729443</td>\n",
       "      <td>0.718914</td>\n",
       "      <td>0.712530</td>\n",
       "      <td>0.720355</td>\n",
       "      <td>0.006394</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.246730</td>\n",
       "      <td>4.138729</td>\n",
       "      <td>2.826756</td>\n",
       "      <td>0.536475</td>\n",
       "      <td>RF</td>\n",
       "      <td>{'model__model': 'RF'}</td>\n",
       "      <td>0.716690</td>\n",
       "      <td>0.695786</td>\n",
       "      <td>0.709486</td>\n",
       "      <td>0.712817</td>\n",
       "      <td>0.713305</td>\n",
       "      <td>0.709617</td>\n",
       "      <td>0.007282</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.790335</td>\n",
       "      <td>2.346710</td>\n",
       "      <td>2.500074</td>\n",
       "      <td>0.387006</td>\n",
       "      <td>DT</td>\n",
       "      <td>{'model__model': 'DT'}</td>\n",
       "      <td>0.669770</td>\n",
       "      <td>0.659194</td>\n",
       "      <td>0.635880</td>\n",
       "      <td>0.658567</td>\n",
       "      <td>0.654943</td>\n",
       "      <td>0.655671</td>\n",
       "      <td>0.011062</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.082330</td>\n",
       "      <td>0.533291</td>\n",
       "      <td>1.906039</td>\n",
       "      <td>0.052334</td>\n",
       "      <td>NB</td>\n",
       "      <td>{'model__model': 'NB'}</td>\n",
       "      <td>0.608113</td>\n",
       "      <td>0.636492</td>\n",
       "      <td>0.623256</td>\n",
       "      <td>0.618817</td>\n",
       "      <td>0.617804</td>\n",
       "      <td>0.620896</td>\n",
       "      <td>0.009231</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "1       9.353714      1.198838         2.517534        0.719666   \n",
       "4       9.493708      0.587190         1.716945        0.320112   \n",
       "2      20.246730      4.138729         2.826756        0.536475   \n",
       "3      12.790335      2.346710         2.500074        0.387006   \n",
       "0       8.082330      0.533291         1.906039        0.052334   \n",
       "\n",
       "  param_model__model                   params  split0_test_score  \\\n",
       "1                SVM  {'model__model': 'SVM'}           0.724249   \n",
       "4                Reg  {'model__model': 'Reg'}           0.715037   \n",
       "2                 RF   {'model__model': 'RF'}           0.716690   \n",
       "3                 DT   {'model__model': 'DT'}           0.669770   \n",
       "0                 NB   {'model__model': 'NB'}           0.608113   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "1           0.738953           0.760413           0.732710           0.736469   \n",
       "4           0.725852           0.729443           0.718914           0.712530   \n",
       "2           0.695786           0.709486           0.712817           0.713305   \n",
       "3           0.659194           0.635880           0.658567           0.654943   \n",
       "0           0.636492           0.623256           0.618817           0.617804   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "1         0.738559        0.012009                1  \n",
       "4         0.720355        0.006394                2  \n",
       "2         0.709617        0.007282                3  \n",
       "3         0.655671        0.011062                4  \n",
       "0         0.620896        0.009231                5  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cv_results.sort_values(by='rank_test_score', ascending=True).head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model__model': 'SVM'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esg-scoring-lewagon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0da4683c4fad0afeec93b8b497065776641c10538c023e7f59ac79d1ec6963bb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
